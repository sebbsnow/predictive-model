{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1 :</b>- Importez les bibliothèques requises et lisez les jeux de données de test et d'entraînement. Ajouter les deux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques requises \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Lire le jeu de données de test et d'entrainement\n",
    "##############################################################\n",
    "######## Changer les chemins vers les jeux de données ########\n",
    "##############################################################\n",
    "train=pd.read_csv('C:/Users/Analytics Vidhya/Desktop/challenge/Train.csv')\n",
    "test=pd.read_csv('C:/Users/Analytics Vidhya/Desktop/challenge/Test.csv')\n",
    "# Create a flag for Train and Test Data set\n",
    "train['Type']='Train' \n",
    "test['Type']='Test'\n",
    "# Assembler les deux\n",
    "fullData = pd.concat([train,test],axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Étape 2 :</b> L'étape 2 du cadre n'est pas requise en Python. Passons à l'étape suivante.\n",
    "\n",
    "<b>Étape 3 :</b> Affichez les noms de colonne / résumé de l'ensemble de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show all the column names\n",
    "fullData.columns \n",
    "\n",
    "# Show first 10 records of dataframe\n",
    "fullData.head(10) \n",
    "\n",
    "#You can look at summary of numerical fields by using describe() function\n",
    "fullData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Étape 4 :</b> Identifiez les a) variables ID b) les variables cibles c) les variables qualitatives d) les variables numériques e) les autres variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_col = ['REF_NO']\n",
    "target_col = [\"Account.Status\"]\n",
    "cat_cols = ['children','age_band','status','occupation','occupation_partner','home_status','family_income','self_employed', 'self_employed_partner','year_last_moved','TVarea','post_code','post_area','gender','region']\n",
    "num_cols= list(set(list(fullData.columns))-set(cat_cols)-set(ID_col)-set(target_col)-set(data_col))\n",
    "other_col=['Type'] #Test and Train Data set identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 5 :<b> Identifiez les variables avec les valeurs manquantes et créez un indicateur pour celles-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will return the feature with True or False,True means have missing value else False\n",
    "fullData.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined numerical and Categorical variables\n",
    "num_cat_cols = num_cols+cat_cols \n",
    "\n",
    "#Create a new variable for each variable having missing value with VariableName_NA \n",
    "# and flag missing value with 1 and other with 0\n",
    "\n",
    "for var in num_cat_cols:\n",
    "    if fullData[var].isnull().any()==True:\n",
    "        fullData[var+'_NA']=fullData[var].isnull()*1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 6 :</b> Imputer les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute numerical missing values with mean\n",
    "fullData[num_cols] = fullData[num_cols].fillna(fullData[num_cols].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute categorical missing values with -9999\n",
    "fullData[cat_cols] = fullData[cat_cols].fillna(value = -9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 7 :</b> Créez des encodeurs de labels pour les variables qualitatives et divisez le jeu de données pour l'apprentissage et le teste, puis divisez le jeu de données d'entrainenement en Train et validez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create label encoders for categorical features\n",
    "for var in cat_cols:\n",
    " number = LabelEncoder()\n",
    " fullData[var] = number.fit_transform(fullData[var].astype('str'))\n",
    "\n",
    "#Target variable is also a categorical so convert it\n",
    "fullData[\"Account.Status\"] = number.fit_transform(fullData[\"Account.Status\"].astype('str'))\n",
    "\n",
    "train=fullData[fullData['Type']=='Train']\n",
    "test=fullData[fullData['Type']=='Test']\n",
    "\n",
    "train['is_train'] = np.random.uniform(0, 1, len(train)) <= .75\n",
    "Train, Validate = train[train['is_train']==True], train[train['is_train']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 8 :</b> Pass the imputed and dummy (missing values flags) variables into the modelling process. I am using random forest to predict the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(set(list(fullData.columns))-set(ID_col)-set(target_col)-set(other_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Train[list(features)].values\n",
    "y_train = Train[\"Account.Status\"].values\n",
    "x_validate = Validate[list(features)].values\n",
    "y_validate = Validate[\"Account.Status\"].values\n",
    "x_test=test[list(features)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 9 :</b> Check performance and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = rf.predict_proba(x_validate)\n",
    "fpr, tpr, _ = roc_curve(y_validate, status[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print roc_auc\n",
    "\n",
    "final_status = rf.predict_proba(x_test)\n",
    "test[\"Account.Status\"]=final_status[:,1]\n",
    "test.to_csv('C:/Users/Analytics Vidhya/Desktop/model_output.csv',columns=['REF_NO','Account.Status'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
